---
title: "Execution-based Code Generation using Deep Reinforcement Learning"
collection: publications
permalink: /publication/2009-10-01-paper-title-number-1
excerpt: 'PPOCoder: A Framework for Improving Code Generation via Pretrained PL Models and Reinforcement Learning with Execution Feedback.'
date: 2023-01-31
venue: 'arXiv'
paperurl: 'https://arxiv.org/abs/2301.13816'
citation: 'Parshin Shojaee, Aneesh Jain, Sindhu Tipirneni and Chandan K. Reddy. (2023). &quot;Execution-based Code Generation using Deep Reinforcement Learning.&quot; <i>arXiv</i>.'
---
The utilization of programming language (PL) models, pretrained on large-scale code corpora, as a means of automating software engineering pro- cesses has demonstrated considerable potential in streamlining various code generation tasks such as code completion, code translation, and program synthesis. However, current approaches mainly rely on supervised fine-tuning objectives borrowed from text generation, neglecting specific sequence- level features of code, including but not limited to compilability as well as syntactic and functional correctness. To address this limitation, we propose PPOCoder, a new framework for code generation that combines pretrained PL models with Proxi- mal Policy Optimization (PPO) deep reinforcement learning and employs execution feedback as the external source of knowledge into the model optimization. PPOCoder is transferable across different code generation tasks and PLs. Extensive ex- periments on three code generation tasks demonstrate the effectiveness of our proposed approach compared to SOTA methods, improving the success rate of compilation and functional correctness over different PLs. Our code can be found [here](https: //github.com/reddy-lab-code-research/PPOCoder).
[Download paper here](http://academicpages.github.io/files/paper1.pdf)

Recommended citation: Parshin Shojaee, Aneesh Jain, Sindhu Tipirneni and Chandan K. Reddy. (2023). "Execution-based Code Generation using Deep Reinforcement Learning." <i>arXiv</i>.